{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, [2, 3]]\n",
    "y = iris.target\n",
    "\n",
    "print('Etykiety klas:', np.unique(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dzielimy dane na 70% przykładów uczących i 30% przykładów testowych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Liczba etykiet w zbiorze y:', np.bincount(y))\n",
    "print('Liczba etykiet w zbiorze y_train:', np.bincount(y_train))\n",
    "print('Liczba etykiet w zbiorze y_test:', np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standaryzacja cech:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uczenie perceptronu za pomocą biblioteki scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "ppn = Perceptron(eta0=0.1, random_state=1)\n",
    "ppn.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Uwaga**\n",
    "\n",
    "- Możesz zastąpić parametr `Perceptron(n_iter, ...)` parametrem `Perceptron(max_iter, ...)` w bibliotece scikit-learn >= 0.19. Celowo wykorzystujemy tu parametr `n_iter`, ponieważ wiele osób ciągle korzysta z wersji 0.18 biblioteki scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ppn.predict(X_test_std)\n",
    "print('Nieprawidłowo sklasyfikowane przykłady: %d' % (y_test != y_pred).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Dokładność: %.3f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dokładność: %.3f' % ppn.score(X_test_std, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_decision_regions(X, y, classifier, test_idx=None, resolution=0.02):\n",
    "\n",
    "    # konfiguruje generator znaczników i mapę kolorów\n",
    "    markers = ('s', 'x', 'o', '^', 'v')\n",
    "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "\n",
    "    # rysuje wykres powierzchni decyzyjnej\n",
    "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
    "                           np.arange(x2_min, x2_max, resolution))\n",
    "    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "    plt.contourf(xx1, xx2, Z, alpha=0.3, cmap=cmap)\n",
    "    plt.xlim(xx1.min(), xx1.max())\n",
    "    plt.ylim(xx2.min(), xx2.max())\n",
    "\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x=X[y == cl, 0], \n",
    "                    y=X[y == cl, 1],\n",
    "                    alpha=0.8, \n",
    "                    c=colors[idx],\n",
    "                    marker=markers[idx], \n",
    "                    label=cl, \n",
    "                    edgecolor='black')\n",
    "\n",
    "    # zaznacza przykłady testowe\n",
    "    if test_idx:\n",
    "        # umieszcza na wykresie wszystkie przykłady\n",
    "        X_test, y_test = X[test_idx, :], y[test_idx]\n",
    "\n",
    "        plt.scatter(X_test[:, 0],\n",
    "                    X_test[:, 1],\n",
    "                    c='cyan',\n",
    "                    edgecolor='black',\n",
    "                    alpha=1.0,\n",
    "                    linewidth=1,\n",
    "                    marker='o',\n",
    "                    s=100, \n",
    "                    label='Zestaw testowy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trenowanie modelu perceptronu za pomocą standaryzowanych danych uczących:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_combined_std = np.vstack((X_train_std, X_test_std))\n",
    "y_combined = np.hstack((y_train, y_test))\n",
    "\n",
    "plot_decision_regions(X=X_combined_std, y=y_combined,\n",
    "                      classifier=ppn, test_idx=range(105, 150))\n",
    "plt.xlabel('Długość płatka [standaryzowana]')\n",
    "plt.ylabel('Szerokość płatka [standaryzowana]')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('rysunki/03_01.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelowanie prawdopodobieństwa przynależności do klasy za pomocą regresji logistycznej"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teoretyczne podłoże regresji logistycznej i prawdopodobieństwa warunkowego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "z = np.arange(-7, 7, 0.1)\n",
    "phi_z = sigmoid(z)\n",
    "\n",
    "plt.plot(z, phi_z)\n",
    "plt.axvline(0.0, color='k')\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.xlabel('z')\n",
    "plt.ylabel('$\\phi (z)$')\n",
    "\n",
    "# y axis ticks and gridline\n",
    "plt.yticks([0.0, 0.5, 1.0])\n",
    "ax = plt.gca()\n",
    "ax.yaxis.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('rysunki/03_02.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='rysunki/03_03.png', width=500) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wyznaczanie wag logistycznej funkcji kosztu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_1(z):\n",
    "    return - np.log(sigmoid(z))\n",
    "\n",
    "\n",
    "def cost_0(z):\n",
    "    return - np.log(1 - sigmoid(z))\n",
    "\n",
    "z = np.arange(-10, 10, 0.1)\n",
    "phi_z = sigmoid(z)\n",
    "\n",
    "c1 = [cost_1(x) for x in z]\n",
    "plt.plot(phi_z, c1, label='J(w) jeżeli y=1')\n",
    "\n",
    "c0 = [cost_0(x) for x in z]\n",
    "plt.plot(phi_z, c0, linestyle='--', label='J(w) jeżeli y=0')\n",
    "\n",
    "plt.ylim(0.0, 5.1)\n",
    "plt.xlim([0, 1])\n",
    "plt.xlabel('$\\phi$(z)')\n",
    "plt.ylabel('J(w)')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "#plt.savefig('rysunki/03_04.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionGD(object):\n",
    "    \"\"\"Klasyfikator regresji logistycznej wykorzystujący metodę gradientu prostego\n",
    "\n",
    "    Parametry\n",
    "    ------------\n",
    "    eta : zmiennoprzecinkowy\n",
    "       Współczynnik uczenia (pomiędzy 0,0 a 1,0)\n",
    "    n_iter : liczba całkowita\n",
    "       Przebiegi po zestawie danych uczących.\n",
    "    random_state : liczba całkowita\n",
    "       Ziarno generatora liczb losowych do losowej inicjalizacji wag.\n",
    "\n",
    "    Atrybuty\n",
    "    -----------\n",
    "    w_ : tablica jednowymiarowa\n",
    "       Wagi po dopasowaniu.\n",
    "    cost_ : lista\n",
    "       Wartość funkcji kosztu (suma kwadratów) w każdej epoce\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, eta=0.05, n_iter=100, random_state=1):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\" Dopasowanie danych uczących.\n",
    "\n",
    "        Parametry\n",
    "        ----------\n",
    "        X : {tablicopodobny}, wymiary = [n_przykładów, n_cech]\n",
    "           Wektory uczenia, gdzie n_przykładów oznacza liczbę przykładów, a\n",
    "           n_cech — liczbę cech.\n",
    "        y : tablicopodobny, wymiary = [n_przykładów]\n",
    "           Wartości docelowe.\n",
    "\n",
    "        Zwraca\n",
    "        -------\n",
    "        self : obiekt\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        rgen = np.random.RandomState(self.random_state)\n",
    "        self.w_ = rgen.normal(loc=0.0, scale=0.01, size=1 + X.shape[1])\n",
    "        self.cost_ = []\n",
    "\n",
    "        for i in range(self.n_iter):\n",
    "            net_input = self.net_input(X)\n",
    "            output = self.activation(net_input)\n",
    "            errors = (y - output)\n",
    "            self.w_[1:] += self.eta * X.T.dot(errors)\n",
    "            self.w_[0] += self.eta * errors.sum()\n",
    "            \n",
    "            # zwróć uwagę, że obliczamy teraz `koszt` logistyczny,\n",
    "            # a nie sumę kwadratów błędów\n",
    "            cost = -y.dot(np.log(output)) - ((1 - y).dot(np.log(1 - output)))\n",
    "            self.cost_.append(cost)\n",
    "        return self\n",
    "    \n",
    "    def net_input(self, X):\n",
    "        \"\"\"Obliczanie pobudzenia całkowitego\"\"\"\n",
    "        return np.dot(X, self.w_[1:]) + self.w_[0]\n",
    "\n",
    "    def activation(self, z):\n",
    "        \"\"\"Obliczanie logistycznej, sigmoidalnej funkcji aktywacji\"\"\"\n",
    "        return 1. / (1. + np.exp(-np.clip(z, -250, 250)))\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Zwraca etykietę klasy po skoku jednostkowym\"\"\"\n",
    "        return np.where(self.net_input(X) >= 0.0, 1, 0)\n",
    "        # jest to równoważne wierszowi:\n",
    "        # return np.where(self.activation(self.net_input(X)) >= 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_01_subset = X_train_std[(y_train == 0) | (y_train == 1)]\n",
    "y_train_01_subset = y_train[(y_train == 0) | (y_train == 1)]\n",
    "\n",
    "lrgd = LogisticRegressionGD(eta=0.05, n_iter=1000, random_state=1)\n",
    "lrgd.fit(X_train_01_subset,\n",
    "         y_train_01_subset)\n",
    "\n",
    "plot_decision_regions(X=X_train_01_subset, \n",
    "                      y=y_train_01_subset,\n",
    "                      classifier=lrgd)\n",
    "\n",
    "plt.xlabel('Długość płatka [standaryzowana]')\n",
    "plt.ylabel('Szerokość płatka [standaryzowana]')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('rysunki/03_05.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uczenie modelu regresji logistycznej za pomocą biblioteki scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(C=100.0, random_state=1, solver='lbfgs', multi_class='ovr')\n",
    "lr.fit(X_train_std, y_train)\n",
    "\n",
    "plot_decision_regions(X_combined_std, y_combined,\n",
    "                      classifier=lr, test_idx=range(105, 150))\n",
    "plt.xlabel('Długość płatka [standaryzowana]')\n",
    "plt.ylabel('Szerokość płatka [standaryzowana]')\n",
    "plt.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "# plt.savefig('rysunki/03_06.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.predict_proba(X_test_std[:3, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.predict_proba(X_test_std[:3, :]).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.predict_proba(X_test_std[:3, :]).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.predict(X_test_std[:3, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.predict(X_test_std[0, :].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zapobieganie przetrenowaniu za pomocą regularyzacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='rysunki/03_07.png', width=700) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, params = [], []\n",
    "for c in np.arange(-5, 5):\n",
    "    lr = LogisticRegression(C=10.**c, random_state=1,\n",
    "                            solver='lbfgs',\n",
    "                            multi_class='ovr')\n",
    "    lr.fit(X_train_std, y_train)\n",
    "    weights.append(lr.coef_[1])\n",
    "    params.append(10.**c)\n",
    "\n",
    "weights = np.array(weights)\n",
    "plt.plot(params, weights[:, 0],\n",
    "         label='Długość płatka')\n",
    "plt.plot(params, weights[:, 1], linestyle='--',\n",
    "         label='Szerokość płatka')\n",
    "plt.ylabel('Współczynnik wag')\n",
    "plt.xlabel('C')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xscale('log')\n",
    "#plt.savefig('rysunki/03_08.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wyznaczanie maksymalnego marginesu za pomocą maszyn wektorów nośnych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='rysunki/03_09.png', width=700) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teoretyczne podłoże maksymalnego marginesu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rozwiązywanie przypadków nieliniowo rozdzielnych za pomocą zmiennych uzupełniających"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='rysunki/03_10.png', width=600) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(kernel='linear', C=1.0, random_state=1)\n",
    "svm.fit(X_train_std, y_train)\n",
    "\n",
    "plot_decision_regions(X_combined_std, \n",
    "                      y_combined,\n",
    "                      classifier=svm, \n",
    "                      test_idx=range(105, 150))\n",
    "plt.xlabel('Długość płatka [standaryzowana]')\n",
    "plt.ylabel('Szerokość płatka [standaryzowana]')\n",
    "plt.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "#plt.savefig('rysunki/03_11.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternatywne implementacje w interfejsie scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "ppn = SGDClassifier(loss='perceptron')\n",
    "lr = SGDClassifier(loss='log')\n",
    "svm = SGDClassifier(loss='hinge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rozwiązywanie nieliniowych problemów za pomocą jądra SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1)\n",
    "X_xor = np.random.randn(200, 2)\n",
    "y_xor = np.logical_xor(X_xor[:, 0] > 0,\n",
    "                       X_xor[:, 1] > 0)\n",
    "y_xor = np.where(y_xor, 1, -1)\n",
    "\n",
    "plt.scatter(X_xor[y_xor == 1, 0],\n",
    "            X_xor[y_xor == 1, 1],\n",
    "            c='b', marker='x',\n",
    "            label='1')\n",
    "plt.scatter(X_xor[y_xor == -1, 0],\n",
    "            X_xor[y_xor == -1, 1],\n",
    "            c='r',\n",
    "            marker='s',\n",
    "            label='-1')\n",
    "\n",
    "plt.xlim([-3, 3])\n",
    "plt.ylim([-3, 3])\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "#plt.savefig('rysunki/03_12.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='rysunki/03_13.png', width=700) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stosowanie sztuczki z funkcją jądra do znajdowania przestrzeni rozdzielających w przestrzeni wielowymiarowej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel='rbf', random_state=1, gamma=0.10, C=10.0)\n",
    "svm.fit(X_xor, y_xor)\n",
    "plot_decision_regions(X_xor, y_xor,\n",
    "                      classifier=svm)\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "#plt.savefig('rysunki/03_14.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(kernel='rbf', random_state=1, gamma=0.2, C=1.0)\n",
    "svm.fit(X_train_std, y_train)\n",
    "\n",
    "plot_decision_regions(X_combined_std, y_combined,\n",
    "                      classifier=svm, test_idx=range(105, 150))\n",
    "plt.xlabel('Długość płatka [standaryzowana]')\n",
    "plt.ylabel('Szerokość płatka [standaryzowana]')\n",
    "plt.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "#plt.savefig('rysunki/03_15.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel='rbf', random_state=1, gamma=100.0, C=1.0)\n",
    "svm.fit(X_train_std, y_train)\n",
    "\n",
    "plot_decision_regions(X_combined_std, y_combined, \n",
    "                      classifier=svm, test_idx=range(105, 150))\n",
    "plt.xlabel('Długość płatka [standaryzowana]')\n",
    "plt.ylabel('Szerokość płatka [standaryzowana]')\n",
    "plt.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "#plt.savefig('rysunki/03_16.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uczenie drzew decyzyjnych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='rysunki/03_17.png', width=500) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='rysunki/03_18.png', width=500) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maksymalizowanie przyrostu informacji — osiąganie jak największych korzyści"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def gini(p):\n",
    "    return p * (1 - p) + (1 - p) * (1 - (1 - p))\n",
    "\n",
    "\n",
    "def entropy(p):\n",
    "    return - p * np.log2(p) - (1 - p) * np.log2((1 - p))\n",
    "\n",
    "\n",
    "def error(p):\n",
    "    return 1 - np.max([p, 1 - p])\n",
    "\n",
    "x = np.arange(0.0, 1.0, 0.01)\n",
    "\n",
    "ent = [entropy(p) if p != 0 else None for p in x]\n",
    "sc_ent = [e * 0.5 if e else None for e in ent]\n",
    "err = [error(i) for i in x]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "for i, lab, ls, c, in zip([ent, sc_ent, gini(x), err], \n",
    "                          ['Entropia', 'Entropia (skalowana)', \n",
    "                           'Wskaźnik Giniego', 'Błąd klasyfikacji'],\n",
    "                          ['-', '-', '--', '-.'],\n",
    "                          ['black', 'lightgray', 'red', 'green', 'cyan']):\n",
    "    line = ax.plot(x, i, label=lab, linestyle=ls, lw=2, color=c)\n",
    "\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, 1.15),\n",
    "          ncol=5, fancybox=True, shadow=False)\n",
    "\n",
    "ax.axhline(y=0.5, linewidth=1, color='k', linestyle='--')\n",
    "ax.axhline(y=1.0, linewidth=1, color='k', linestyle='--')\n",
    "plt.ylim([0, 1.1])\n",
    "plt.xlabel('p(i=1)')\n",
    "plt.ylabel('Wskaźnik zanieczyszczenia')\n",
    "#plt.savefig('rysunki/03_19.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Budowanie drzewa decyzyjnego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree_model = DecisionTreeClassifier(criterion='gini', \n",
    "                                    max_depth=4, \n",
    "                                    random_state=1)\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "X_combined = np.vstack((X_train, X_test))\n",
    "y_combined = np.hstack((y_train, y_test))\n",
    "plot_decision_regions(X_combined, y_combined, \n",
    "                      classifier=tree_model,\n",
    "                      test_idx=range(105, 150))\n",
    "\n",
    "plt.xlabel('Długość płatka [cm]')\n",
    "plt.ylabel('Szerokość płatka [cm]')\n",
    "plt.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "#plt.savefig('rysunki/03_20.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "tree.plot_tree(tree_model)\n",
    "#plt.savefig('rysunki/03_21_1.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydotplus import graph_from_dot_data\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "dot_data = export_graphviz(tree_model,\n",
    "                           filled=True, \n",
    "                           rounded=True,\n",
    "                           class_names=['Setosa', \n",
    "                                        'Versicolor',\n",
    "                                        'Virginica'],\n",
    "                           feature_names=['Długość płatka', \n",
    "                                          'Szerokość płatka'],\n",
    "                           out_file=None) \n",
    "graph = graph_from_dot_data(dot_data) \n",
    "graph.write_png('drzewo.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='rysunki/03_21.png', width=600) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Łączenie wielu drzew decyzyjnych za pomocą modelu losowego lasu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(criterion='gini',\n",
    "                                n_estimators=25, \n",
    "                                random_state=1,\n",
    "                                n_jobs=2)\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "plot_decision_regions(X_combined, y_combined, \n",
    "                      classifier=forest, test_idx=range(105, 150))\n",
    "\n",
    "plt.xlabel('Długość płatka [cm]')\n",
    "plt.ylabel('Szerokość płatka [cm]')\n",
    "plt.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "#plt.savefig('rysunki/03_22.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorytm k-najbliższych sąsiadów — model leniwego uczenia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='rysunki/03_23.png', width=400) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5, \n",
    "                           p=2, \n",
    "                           metric='minkowski')\n",
    "knn.fit(X_train_std, y_train)\n",
    "\n",
    "plot_decision_regions(X_combined_std, y_combined, \n",
    "                      classifier=knn, test_idx=range(105, 150))\n",
    "\n",
    "plt.xlabel('Długość płatka [standaryzowana]')\n",
    "plt.ylabel('Szerokość płatka [standaryzowana]')\n",
    "plt.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "#plt.savefig('rysunki/03_24.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Podsumowanie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Czytelnicy mogą zignorować poniższą komórkę."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python ../.convert_notebook_to_script.py --input r03.ipynb --output r03.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
